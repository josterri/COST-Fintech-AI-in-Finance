<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3 - COST Action CA19130</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Source+Code+Pro:wght@400;500&display=swap" rel="stylesheet">
    <style>
        :root {
            --cost-purple: #5B2D8A;
            --cost-blue: #2B5F9E;
            --cost-teal: #00A0B0;
            --cost-orange: #E87722;
            --dark: #1a1a2e;
            --light: #f8f9fa;
            --gray: #6c757d;
            --border: #dee2e6;
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: 'Inter', sans-serif; line-height: 1.6; color: var(--dark); background: var(--light); }
        nav { background: linear-gradient(135deg, var(--cost-purple), var(--cost-blue)); padding: 1rem 2rem; position: fixed; width: 100%; top: 0; z-index: 1000; }
        nav .nav-content { max-width: 1400px; margin: 0 auto; display: flex; justify-content: space-between; align-items: center; }
        nav .logo { color: white; font-weight: 700; font-size: 1.2rem; }
        nav .logo span { color: var(--cost-orange); }
        nav ul { display: flex; list-style: none; gap: 2rem; }
        nav a { color: rgba(255,255,255,0.9); text-decoration: none; font-size: 0.9rem; font-weight: 500; }
        nav a:hover { color: white; }
        .header { background: linear-gradient(135deg, var(--cost-purple), var(--cost-blue)); color: white; padding: 6rem 2rem 2rem; }
        .header h1 { font-size: 1.8rem; max-width: 1200px; margin: 0 auto 0.5rem; }
        .header .meta { font-size: 0.9rem; opacity: 0.8; max-width: 1200px; margin: 0 auto; }
        .breadcrumb { background: white; padding: 1rem 2rem; border-bottom: 1px solid var(--border); }
        .breadcrumb-content { max-width: 1200px; margin: 0 auto; font-size: 0.85rem; }
        .breadcrumb a { color: var(--cost-purple); text-decoration: none; }
        .breadcrumb span { color: var(--gray); }
        .content { max-width: 1200px; margin: 0 auto; padding: 2rem; }
        .document { background: white; border-radius: 12px; box-shadow: 0 4px 20px rgba(0,0,0,0.08); overflow: hidden; }
        .doc-header { background: linear-gradient(135deg, rgba(91,45,138,0.05), rgba(43,95,158,0.05)); padding: 1.5rem 2rem; border-bottom: 1px solid var(--border); display: flex; justify-content: space-between; align-items: center; flex-wrap: wrap; gap: 1rem; }
        .doc-header h2 { color: var(--cost-purple); font-size: 1.1rem; }
        .doc-stats { display: flex; gap: 1.5rem; font-size: 0.85rem; color: var(--gray); }
        .doc-stats span { display: flex; align-items: center; gap: 0.3rem; }
        .doc-body { padding: 2rem; }
        .page-break { border-top: 2px dashed var(--border); margin: 2rem 0; padding-top: 1rem; }
        .page-break::before { content: attr(data-page); display: inline-block; background: var(--cost-purple); color: white; padding: 0.2rem 0.8rem; border-radius: 12px; font-size: 0.75rem; font-weight: 600; }
        .text-content { font-family: 'Source Code Pro', monospace; font-size: 0.85rem; line-height: 1.8; white-space: pre-wrap; word-wrap: break-word; color: #333; }
        .text-content .highlight { background: rgba(232,119,34,0.15); padding: 0.1rem 0.3rem; border-radius: 3px; }
        .toc { background: white; border-radius: 12px; padding: 1.5rem 2rem; margin-bottom: 1.5rem; box-shadow: 0 4px 20px rgba(0,0,0,0.08); }
        .toc h3 { color: var(--cost-purple); margin-bottom: 1rem; font-size: 1rem; }
        .toc ul { list-style: none; }
        .toc li { margin-bottom: 0.5rem; }
        .toc a { color: var(--cost-blue); text-decoration: none; font-size: 0.9rem; }
        .toc a:hover { text-decoration: underline; }
        .download-btn { display: inline-flex; align-items: center; gap: 0.5rem; background: var(--cost-purple); color: white; padding: 0.6rem 1.2rem; border-radius: 8px; text-decoration: none; font-size: 0.85rem; font-weight: 500; }
        .download-btn:hover { background: #4a2470; }
        .search-box { margin-bottom: 1.5rem; }
        .search-box input { width: 100%; padding: 0.8rem 1rem; border: 2px solid var(--border); border-radius: 8px; font-size: 0.9rem; }
        .search-box input:focus { outline: none; border-color: var(--cost-purple); }
        footer { background: var(--dark); color: white; padding: 2rem; text-align: center; margin-top: 3rem; }
        footer a { color: var(--cost-orange); text-decoration: none; }
        @media (max-width: 768px) { nav ul { display: none; } .header h1 { font-size: 1.4rem; } .doc-body { padding: 1rem; } }
    </style>
</head>
<body>
    <nav>
        <div class="nav-content">
            <div class="logo">COST <span>CA19130</span></div>
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="documents.html">Documents</a></li>
                <li><a href="midterm-report.html">Mid-Term Report</a></li>
            </ul>
        </div>
    </nav>

    <header class="header">
        <h1>3</h1>
        <div class="meta">Source: 3.txt | Generated: 2026-01-02 20:41</div>
    </header>

    <div class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="index.html">Home</a> <span>/</span>
            <a href="documents.html">Documents</a> <span>/</span>
            <span>3</span>
        </div>
    </div>

    <main class="content">
        <div class="search-box">
            <input type="text" id="searchInput" placeholder="Search in document..." onkeyup="searchDocument()">
        </div>

        <div class="document">
            <div class="doc-header">
                <h2>Document Content</h2>
                <div class="doc-stats">
                    <span>6 pages</span>
                    <span>13,052 characters</span>
                    <span>2,095 words</span>
                </div>
            </div>
            <div class="doc-body" id="documentBody">
<div class="page-break" data-page="Page 1"></div><pre class="text-content">
Detection of fraudulent users in P2P financial
market
Hao Wang*
HC Research, HC Financial Service Group, China
Abstract. Financial fraud detection is one of the core technological assets
of Fintech companies. It saves tens of millions of money from Chinese
Fintech companies since the bad loan rate is more than 10%. HC Financial
Service Group is the 3rd largest company in the Chinese P2P financial
market. In this paper we illustrate how we tackle the fraud detection
problem at HC Financial. We utilize two powerful workhorses in the
machine learning field - random forest and gradient boosting decision tree
to detect fraudulent users. We demonstrate that by carefully select features
and tune model parameters, we could effectively filter out fraudulent users
in the P2P market.
1 Introduction
Fintech is one of the most thriving industry in many countries over the world. People have
been relying on Fintech to lend and borrow money , detect fraudulent users , match loans
between money lenders and borrowers. P2P is a business model where money lenders can
distribute his investment over multiple borrowers and each borrower could gather money
from a host of money lenders. P2P has been extremely popular in China with an annual
interest return rate of 8% - 10% satisfying to most of P2P sites’ users.
Major P2P companies in China have been using a technology called knowledge graph to
facilitate their financial processes. Knowledge graph is a graph constructed from data
collected from the internet with user’s authorization, including the user’s phone log , ID
card information, bank account transactions, home addresses, etc. Each node in knowledge
graph represents entity such as person, id card number, address etc. , while each edge
represents relationship such as colleagues, family membership, etc. Knowledge graph is
one of the core assets of P2P companies because it is highly useful in crucial business
processes within the company. For example, knowledge graph could be used to do anti-
fraud , which saves tens of millions of money given the bad loan rate is close to 50% on
most of the P2P platforms.
HC Financial Service Group is one of the top P2P companies in China. We have a fully
built team consisting of nearly 100 staff working on credit risk modeling problems taking
advantage of more than 400 million users’ information. Credit risk modeling problems ,
when solved in machine learning contexts, are conventionally modeled as class imbalance
problems. Most of the time , feature engineering and graph pattern analysis play a key role
* Corresponding author: haow85@live.com
© The Authors, published by EDP Sciences. This is an open access article distributed under the terms of the Creative Commons 
Attribution License 4.0 (http://creativecommons.org/licenses/by/4.0/).
MATEC Web of Conferences 189, 06004 (2018)	
 https://doi.org/10.1051/matecconf/201818906004
MEAMT 2018


</pre><div class="page-break" data-page="Page 2"></div><pre class="text-content">
in the problem solving process. Case-by-case and manual inspection of individual node and
its neighbors in extremely large knowledge graph is daily routine of credit risk modeling
team’s work.
One advantage of the problem setting in P2P financial market is that the fraud rate is
very high - as high as more than 10% , some times a lot higher. The high fraud rate causes
big headache for company runners but saves the day for algorithm engineers since class
imbalance problem is a lot less severe. In this paper, we demonstrate that using random
forest and gradient boosting decision tree, we could obtain evaluation metrics comparable
to non-class imbalance problems.
2 Related work
Fraudulent behavior exists since the advent of internet. Special groups and teams of internet
companies and educational institutes are formed to tackle various fraudulent behavior.
Facebook designed an algorithm called CopyCatch [1] to detect the Lockstep behavior.
Later they came up with a new invention called SynchroTrap [2] to detect synchronized
attack. CMU researchers invented fBox [3] and SpokeEigen [4] algorithms to detect
community fraud.
Fraud detection is one of the most extensively researched field in Fintech industry.
Common fraud detection methods include rule-based approaches, Bayesian networks and
machine learning techniques. Fraud detection, when formulated as a classification problem,
is inherently a class imbalance problem very difficult to solve. Therefore in practice expert
domain knowledge has become one of the most important ingredients of the Fintech fraud
detection system.
Vlasselaer et al. [5] provided a machine learning framework for graph-based financial
fraud detection in general. They pointed out that graph pattern mining alone is seldom used
as a standalone model for financial fraud detection. Graph patterns usually serve as features
to classification models such as random Logistic regression.
3 Algorithm
Feature engineering is a crucial step in credit risk modeling . Selection and processing of
the appropriate features is a delicate art. At HC Financial Group, we have both online and
offline systems where we could store detailed information about money borrowers. For
example, at our outlet in Beijing, our sales staff help customers input their information into
our systems. Once the information is entered, our online system will ask the user to
authorize us to acquire other information about the user such as the credit report from the
People’s Bank of China. We have hundreds of data items we could use for each user in our
systems.
However, not every data item store in our system is necessary in our credit risk
modeling processes. In our problem context, we select the following features as input to our
models:
1. Financial information : Features in this group include user’s personal income , car
rent , house rent , etc.
2
MATEC Web of Conferences 189, 06004 (2018)	
 https://doi.org/10.1051/matecconf/201818906004
MEAMT 2018


</pre><div class="page-break" data-page="Page 3"></div><pre class="text-content">
2. Work information : Features in this group include user’s company’s income , how
long the company has been founded, etc.
3. Transaction information : Features in this group include the amount of money user
borrows in the transaction , whether the user has submitted applications before , etc.
4. Demographic information: Features in this group include the number of family
members of the user, etc.
We chose these 4 groups of features because they are both heuristically and empirically
consistent with our mission. For categorical data in the features, we utilize one-hot
encodings to expand the term into several terms consisting of either 1 or 0. There are 97
selected features in total with 33 being categorical features.
To compare different feature engineering results, we use original data , data with PCA
dimensionality reduction , data with tanh conversion , among many other feature
engineering schemas. We would like to try PCA because after one-hot encoding, the feature
space is expanded into hundreds of dimensions. We explore tanh because of the sharp
contrast in the magnitudes of different features.
We use two of the most powerful workhorses in the machine learning field to detect the
fraud users - random forest and gradient boosting decision tree. We choose these two
models because they provide easy-to-tune parameters and robust results.
Random forest is an ensemble learning algorithm that aggregates the results from a
group of regression or classification trees. The parameters that needs to be tuned include the
maximum depth of each tree and the total number of trees in the forest.
Gradient boosting decision tree (GBDT) is one of the most successful gradient boosting
algorithmic paradigms. The general work flow of a gradient boosting algorithm [6] is listed
in Figure 1. GBDT utilizes the general gradient boosting schema with trees as its
elementary components. The parameters that needs to be tuned include the maximum depth
of each boosting tree, learning rate of the algorithm , number of trees in the model, etc.
To evaluate our algorithms, we use the AUC metric. We choose AUC because it is
insensitive to class balance ratio. AUC measures the area of the ROC curve. A random
classification result is close to 0.5. A perfect classification result is close to 1.0. The higher
the value of the AUC, the better the classification result is.
The major toolkit we use to develop and test our algorithms is scikit-learn and xgboost.
4 Experiment
3
MATEC Web of Conferences 189, 06004 (2018)	
 https://doi.org/10.1051/matecconf/201818906004
MEAMT 2018


</pre><div class="page-break" data-page="Page 4"></div><pre class="text-content">
We select two datasets to test our algorithms : One consists of 30K normal users and 30K
users with overdue payments (dataset A) , the other consists of 50K users consisting of 25K
fraud users and 25K normal users (dataset B) . We split our dataset into training set, test set
and validation set with the ratio of 4:1:1.
In our random forest algorithm, we enumerate the values of the maximum depth of each
tree and the number of trees in the model. Figure 1 illustrates the scatter plot visualizing the
results (AUC) of random forest + PCA dataset A. Maximum depths of trees are enumerated
between 2 and 5 while the number of trees in the forest is enumerated between 5 and 120 .
As shown in the figure, AUC increases with max depths until it reaches the value of 4. It is
comparatively insensitive to the number of trees in the forest.
Figure 2 visualizes the change of parameters with function tanh applied to features so
they become normalized. Tanh generates better results than PCA only or PCA and tanh
combined , with the average AUC being 0.780 on test set and 0.797 on validation set.
Fig. 1. Scatter plot of random forest + PCA on dataset A.
Fig. 2. Scatter plot of random forest + tanh on dataset A.
We also test random forest on dataset B. We enumerate the maximum depths and
number of trees as the parameters to the random forest algorithm. Figure 3 shows the result
with tanh function applied to the features . Similar to our result on dataset A, tanh alone
generates better results than PCA or PCA and tanh combined.The average AUC metrics on
both test and validation sets are 0.83.
Figure 4 shows the results of tanh applied to GBDT input feautres on dataset B. After
having eliminated a few AUC outliers, the average AUC on both test and validation sets
yields values close to 0.88.
In both data sets, PCA generates more consistent AUC metric per each parameter
compared to the same algorithm on plain data set. However , tanh operation on features
4
MATEC Web of Conferences 189, 06004 (2018)	
 https://doi.org/10.1051/matecconf/201818906004
MEAMT 2018


</pre><div class="page-break" data-page="Page 5"></div><pre class="text-content">
yield better scores than PCA only or PCA / tanh combined on both data sets. We see from
our experimental results, partially due to the nice data structure, simple tweaks after careful
feature selection could lead to results usable for our online systems.
Fig. 3. Scatter plot of random forest + tanh on dataset B.
Fig. 4. Scatter plot of GBDT + tanh on dataset B.
5 Conclusion
Fraud and overdue payment users detection is a crucial step in Fintech company’s business
processes. Effective filter-out of such users could save tens of millions of US dollars for the
company. In this paper we propose using feature engineering and random forest / GBDT
algorithms to detect fraudulent users in P2P financial market. Due to the high fraud rate in
the market (more than 10%), it is comparatively easy to generate satisfying results
compared to other markets like conventional banking systems where the fraud rate could be
as low as 2%. We tested our algorithms on two real world data sets and visualized the AUC
metric together with the selection of model parameters.
In future work, we would like to explore the possibility of taking advantage of deep
learning techniques to detect fraud and overdue payment users in our systems. Deep
learning has been effectively and ubiquitously used in a whole spectrum of machine
learning tasks. The expectation of better evaluation metric results could never be
underestimated.
5
MATEC Web of Conferences 189, 06004 (2018)	
 https://doi.org/10.1051/matecconf/201818906004
MEAMT 2018


</pre><div class="page-break" data-page="Page 6"></div><pre class="text-content">
References
1.
A. Beutel, W. Xu, V. Guruswami, C. Palow and C. Faloutsos, “CopyCatch: Stopping
Group Attacks by Spotting Lockstep Behavior in Social Networks” WWW’13
2.
Q. Cao, X. Yang, J. Yu and C. Palow, “Uncovering Large Groups of Active Malicious
Accounts in Online Social Networks” CCS’14
3.
N. Shah, A. Beutel, B. Gallagher, C. Faloutsos, “Spotting Suspicious Link Behavior
with fBox : An Adversarial Perspective” ICDM’14
4.
B. Prakash, A. Sridharan, M. Seshadri, S.Machiraju, C. Faloutsos, “EigenSpokes:
Surprising Patterns and Scalable Community Chipping in Large Graphs” PAKDD’10
5.
V. Vlasselaer, T. Eliassi-Rad, L. Akoglu, M. Snoeck, B. Baesens, “GOTCHA!
Network-based Fraud Detection for Social Security Fraud” Management Science’14
6.
https://en.wikipedia.org/wiki/Gradient_boosting
6
MATEC Web of Conferences 189, 06004 (2018)	
 https://doi.org/10.1051/matecconf/201818906004
MEAMT 2018
</pre>
            </div>
        </div>
    </main>

    <footer>
        <p>COST Action CA19130 - Fintech and AI in Finance</p>
        <p><a href="https://fin-ai.eu" target="_blank">fin-ai.eu</a> | <a href="https://www.cost.eu/actions/CA19130/" target="_blank">COST Website</a></p>
    </footer>

    <script>
        function searchDocument() {
            const input = document.getElementById('searchInput').value.toLowerCase();
            const content = document.getElementById('documentBody');

            // Remove existing highlights
            content.innerHTML = content.innerHTML.replace(/<mark class="highlight">([^<]+)<\/mark>/gi, '$1');

            if (input.length < 2) return;

            // Add new highlights
            const regex = new RegExp('(' + input.replace(/[.*+?^${}()|[\]\\]/g, '\\$&') + ')', 'gi');
            content.innerHTML = content.innerHTML.replace(regex, '<mark class="highlight">$1</mark>');
        }
    </script>
</body>
</html>