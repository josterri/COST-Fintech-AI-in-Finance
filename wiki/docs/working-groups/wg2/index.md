# WG2: Transparent versus Black Box Decision-Support Models

## Overview

**Leader**: Prof Petre Lameski (Ss. Cyril and Methodius University)

**Participants**: 254 researchers from 40+ countries

Making black-box machine learning models transparent and interpretable. Focus on Explainable AI (XAI), credit risk modeling, fairness in ML, and model robustness.

## Research Focus

- Explainable AI (XAI) methods
- Credit risk scoring transparency
- Model interpretability techniques
- Fairness in machine learning
- Algorithmic bias detection
- Model robustness and reliability
- Feature importance analysis
- Counterfactual explanations

## Key Deliverables

- D2: Best Practices Report
- D7: AI Testing Position Papers
- D8: Real-time AI Testing Criteria
- D11: Stress Testing Methodology

## Activities

### Meetings
WG2 organized regular meetings including:
- Dedicated WG sessions at Action conferences
- Virtual working meetings
- Joint sessions with other WGs

### Publications
WG2 members produced 300+ publications in leading journals and conferences.

[View WG2 Publications](publications.md){ .md-button }

### Member List
[View WG2 Members](members.md){ .md-button }

## Collaboration

WG2 actively collaborated with:
- Other Working Groups within the Action
- External research networks
- Industry partners
- Regulatory bodies
