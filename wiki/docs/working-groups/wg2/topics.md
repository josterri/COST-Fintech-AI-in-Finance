# WG2 Research Topics

## Transparent vs Black Box Decision-Support Models

**Leader**: Dr. Petre Lameski

Development of conceptual and methodological tools for making black-box models transparent or interpretable/explainable. Focus on XAI approaches, credit risk modeling, and ML model robustness.

## Key Research Topics

### Explainable AI

**Explainable AI (XAI) Frameworks**

Making black-box models transparent and interpretable:

- Post-hoc explanation methods (SHAP, LIME, etc.)
- Intrinsically interpretable models for finance
- Contrastive and counterfactual explanations
- Human-AI interaction and explanation interfaces

### Credit Risk

**Credit Risk Model Interpretability**

Enhancing transparency in credit decisions:

- Explainable credit scoring systems
- Regulatory compliance (GDPR Article 22, SR 11-7)
- Adverse action explanations and recourse
- Bias detection in lending algorithms

### Model Interpretability

**ML Model Interpretability**

General approaches to model transparency:

- Feature importance and attribution methods
- Model-agnostic interpretation techniques
- Visualization methods for complex models
- Uncertainty quantification and confidence

### Decision Support

**Transparent Decision Support Systems**

Building interpretable financial decision tools:

- Algorithmic trading transparency
- Robo-advisor explainability
- Insurance underwriting transparency
- Portfolio allocation explanation

### ML Robustness

**ML Model Robustness Testing**

Ensuring model reliability and fairness:

- Adversarial robustness in financial models
- Fairness testing across demographic groups
- Model stability under distribution shift
- Stress testing ML-based systems

---

## Related Resources

- [WG2 Publications](publications.md)
- [WG2 Members](members.md)
- [Back to WG2 Overview](index.md)